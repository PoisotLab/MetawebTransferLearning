{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2 - tree cleaning"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Phylo\n",
    "using GBIF\n",
    "using CSV, DataFrames\n",
    "using ProgressMeter\n",
    "using Base.Threads"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we have made a number of matches in the previous step, we want to make\n",
    "sure that the tree names are *entirely* reconciled to the GBIF version of the\n",
    "European metaweb names."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tree = open(parsenexus, joinpath(\"data\", \"mammals.nex\"))[\"*UNTITLED\"]\n",
    "treenodes = [n.name for n in tree.nodes if !startswith(n.name, \"Node \")]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the same basic approach as for the metaweb name matching, *i.e.* a\n",
    "collection of data frames meant to make the name cleaning thread-safe."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tree_cleanup_components = [\n",
    "    DataFrame(; code=String[], gbifname=String[], gbifid=Int64[], equal=Bool[]) for\n",
    "    i in 1:nthreads()\n",
    "]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code is, again, similar to the previous step - the only difference is\n",
    "that we need to get rid of the `_` that phylogeny files love so much."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = Progress(length(treenodes))\n",
    "@threads for i in 1:length(treenodes)\n",
    "    cname = replace(treenodes[i], '_' => ' ')\n",
    "    try\n",
    "        tax = GBIF.taxon(cname; strict=false, class=\"Mammalia\")\n",
    "        push!(\n",
    "            tree_cleanup_components[threadid()],\n",
    "            (treenodes[i], tax.species[1], tax.species[2], cname == tax.species[1]),\n",
    "        )\n",
    "    catch\n",
    "        continue\n",
    "    end\n",
    "    next!(p)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As previously, we create a new artifact (note that it is not merged to the\n",
    "reconciled metaweb names - we are mostly accumulating keys for joins at this\n",
    "point)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tree_cleanup = vcat(tree_cleanup_components...)\n",
    "CSV.write(joinpath(\"artifacts\", \"upham_gbif_names.csv\"), tree_cleanup)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
