{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6 - inflating the predictions with the Newfoundland data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using DelimitedFiles\n",
    "using DataFrames\n",
    "using CSV: CSV\n",
    "using GBIF\n",
    "using NCBITaxonomy: NCBITaxonomy\n",
    "using EcologicalNetworks"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by reading the Newfoundland food web, and check the names that are\n",
    "mammals. The actual code to read the network looks exactly like the one to\n",
    "read the European metaweb."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sl_raw = readdlm(\"data/NLfoodweb.csv\", ',')\n",
    "\n",
    "sl_sp = replace.(sl_raw[1, 2:end], \".\" => \" \")\n",
    "sl_A = Bool.(sl_raw[2:end, 2:end])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because the original data use a mix of scientific and vernacular names, we are\n",
    "going to rely on `NCBITaxonomy.jl. synonym matching abilities to first get the\n",
    "taxonomic names, and then pass those to GBIF.  Please do keep in mind that\n",
    "unless the `NCBITAXONOMY_PATH` environmental variable is set, the raw taxonomy\n",
    "dump will be stored in the project folder (and this is a rather big file)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scinames = Dict{String,String}()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we do *not* restrict the name matching to only mammals, as there are\n",
    "non-mammal species in the Newfoundland metaweb."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for s in sl_sp\n",
    "    try\n",
    "        t = NCBITaxonomy.taxon(s; strict=false)\n",
    "        scinames[s] = t.name\n",
    "    catch\n",
    "        @info \"Newfoundland taxon $(s) unmatched on NCBI\"\n",
    "        continue\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to get the names from NCBI, and match them to the GBIF\n",
    "backbone. We ended up relying on this two-step solution because using the GBIF\n",
    "name matching directly missed a handful of species, and the Newfoundland\n",
    "dataset is relatively small."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This loop will go through all nodes in the Newfoundland metaweb, match them at\n",
    "the species level, and only return them if they are part of the *Mammalia*\n",
    "class. There may be a few info messages about unmatched taxa, which are nodes\n",
    "from the original data that are at a higher rank than species."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "valnames = Dict{String,String}()\n",
    "for (s, t) in scinames\n",
    "    gbifmatch = GBIF.taxon(t; strict=false)\n",
    "    if !isnothing(gbifmatch)\n",
    "        if !ismissing(gbifmatch.species)\n",
    "            if gbifmatch.class.first == \"Mammalia\"\n",
    "                valnames[s] = gbifmatch.species.first\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the two dictionaries, we can get the positions of species from the\n",
    "Newfoundland metaweb that are mammals:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "idxmatch = findall(x -> x in keys(valnames), sl_sp)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can now assemble the network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "spnames = [valnames[s] for s in sl_sp[idxmatch]]\n",
    "A = sl_A[idxmatch, idxmatch]'\n",
    "NL = UnipartiteNetwork(A, spnames)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally save the network as a CSV - note that we do not add interactions\n",
    "here, as this will be done as part of the thresholding step, which is the very\n",
    "last in the pipeline."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = DataFrame(; from=String[], to=String[])\n",
    "for i in interactions(NL)\n",
    "    push!(df, (i.from, i.to))\n",
    "end\n",
    "CSV.write(\"artifacts/newfoundland.csv\", df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
